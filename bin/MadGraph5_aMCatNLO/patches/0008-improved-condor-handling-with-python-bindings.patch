--- a/madgraph/various/cluster.py
+++ b/madgraph/various/cluster.py

@@ -849,7 +848,131 @@
     name = 'condor'
     job_id = 'CONDOR_ID'
 
+    def __init__(self, *args, **opt):
+        """Init the cluster """
+
+        super(CondorCluster, self).__init__(self, *args, **opt)
+        try:
+            import htcondor
+            self.schedd = htcondor.Schedd()
+            self._action = htcondor.JobAction
+        except Exception, error:
+            raise ClusterManagmentError, 'could not import htcondor python API: \n%s' % error
+        self.hold_list = os.environ.get("CONDOR_RELEASE_HOLDCODES", "")
+        self.max_shadows = os.environ.get("CONDOR_RELEASE_HOLDCODES_SHADOW_LIM", "")
+        self.walltimes = os.environ.get("CONDOR_SET_MAXWALLTIMES", "")
+
+    def query(self, ids, ads=[], lim=-1):
+        """Query the Schedd via HTCondor Python API"""
+        q = self.schedd.query(
+            'stringListmember(string(ClusterId),"{0}")'.format(
+                ",".join(str(id) for id in ids)), ads, limit=lim)
+        return q
+
+    def edit(self, ids, ad, value):
+        """ Edit a single parameter classAd in a list of ClusterIds"""
+        q = self.schedd.edit(
+            'stringListmember(string(ClusterId), "{0}")'.format(
+                ",".join(str(id) for id in ids)), str(ad), str(value))
+        return q
+
+    def status_map(self, status):
+        if status == 0:
+            return 'U'
+        elif status == 1:
+            return 'I'
+        elif status == 2:
+            return 'R'
+        elif status == 3:
+            return 'X'
+        elif status == 4:
+            return 'C'
+        elif status == 5:
+            return 'H'
+        elif status == 6:
+            return 'E'
+        else:
+            return str(status)
+
+    def _release_holdcode(self, id, holdcode, holdsubcode):
+        """ Automatically release job if it is held with the specified
+        hold code and subcode"""
+        q = self.query([str(id)], ["JobStatus", "HoldReasonCode", "HoldReasonSubCode"], lim=1)
+        if len(q)>0:
+            status = self.status_map(q[0]["JobStatus"])
+        else:
+            return False
+
+        if status == 'H':
+            job_hold_code = q[0]["HoldReasonCode"]
+            job_hold_subcode = q[0]["HoldReasonSubCode"]
+            if (job_hold_code == holdcode) and (job_hold_subcode == holdsubcode or holdsubcode == -1):
+                logger.info("ClusterId {0} was held with code {1}, subcode {2}. Releasing it.".format(id, job_hold_code, job_hold_subcode))
+                self.schedd.act(self._action.Release, "ClusterId =?= {0}".format(id))
+                return True
+        return False
 
+    def release_holdcodes(self, id, holdcodes_list, numshadow_limit=10):
+        """ Automatically release job if it is held with any of the specified
+        list of hold codes and subcodes. The convention is hold_code:hold_subcode
+        separated by a comma.If no hold_subcode is specified, only hold_code is
+        taken into account. E.g:
+        holdcodes_list="26:119,13,30:1"
+        """
+        if not isinstance(holdcodes_list, (str, unicode)):
+            logger.info("Holdcodes_list is not a string.")
+            return False
+
+        q = self.query([str(id)], ["NumShadowStarts"], lim=1)
+        num_shadow_starts = q[0]["NumShadowStarts"] if "NumShadowStarts" in q[0] else 0
+        if num_shadow_starts > numshadow_limit:
+            return False
+
+        holdcodes_list = holdcodes_list.split(",")
+        for holdcodes in holdcodes_list:
+            holdcodes = holdcodes.split(":")
+            if False in [i.strip().isdigit() for i in holdcodes]:
+                logger.info("Could not parse holdcodes list, please verify the format.")
+                return False
+            holdcode = int(holdcodes[0].strip())
+            holdsubcode = int(holdcodes[1].strip()) if len(holdcodes)>=2 else -1
+            if self._release_holdcode(id, int(holdcode), int(holdsubcode)):
+                return True
+        return False
+
+    def update_maxwalltime(self, id, walltimes_minutes):
+        """ Automatically increase MaxWallTimeMins classAd from condor job
+        if such job was evicted because its current max promised time was not enough.
+        E.g: walltimes_min="480,960,2400"
+        """
+        if not isinstance(walltimes_minutes, (str, unicode)):
+            return 0
+        else:
+            walltimes_minutes = walltimes_minutes.split(",")
+
+        if False in [i.isdigit() for i in walltimes_minutes]:
+            return 0
+
+        q = self.query([str(id)], ["JobDuration", "MaxWallTimeMins", "LastMaxWalltimeUpdate_JobDuration"], lim=1)
+        job_maxwalltime = q[0]["MaxWallTimeMins"] if "MaxWallTimeMins" in q[0] else 0
+        if hasattr(job_maxwalltime, "eval"):
+            job_maxwalltime = job_maxwalltime.eval()
+        job_duration = q[0]["JobDuration"] if "JobDuration" in q[0] else -1.0
+        last_update_job_duration = \
+                q[0]["LastMaxWalltimeUpdate_JobDuration"] if "LastMaxWalltimeUpdate_JobDuration" in q[0] else -1.0
+
+        if job_duration > job_maxwalltime*60 and job_duration != last_update_job_duration:
+            remaining_walltimes = [int(i) for i in walltimes_minutes
+                                   if int(i) > int(job_maxwalltime) and
+                                   int(i) > (int(job_duration / 60) + int((job_duration / 60) % 1 > 0))]
+
+            if remaining_walltimes:
+                new_maxwalltime = min(remaining_walltimes)
+                self.edit([str(id)], "LastMaxWalltimeUpdate_JobDuration", job_duration)
+                self.edit([str(id)], "MaxWallTimeMins", new_maxwalltime)
+                return new_maxwalltime
+
+        return 0
 
     @multiple_try()
     def submit(self, prog, argument=[], cwd=None, stdout=None, stderr=None, log=None,
@@ -1007,54 +1130,61 @@
     @multiple_try(nb_try=10, sleep=10)
     def control_one_job(self, id):
         """ control the status of a single job with it's cluster id """
-        cmd = 'condor_q '+str(id)+" -format \'%-2s \\n\' \'ifThenElse(JobStatus==0,\"U\",ifThenElse(JobStatus==1,\"I\",ifThenElse(JobStatus==2,\"R\",ifThenElse(JobStatus==3,\"X\",ifThenElse(JobStatus==4,\"C\",ifThenElse(JobStatus==5,\"H\",ifThenElse(JobStatus==6,\"E\",string(JobStatus))))))))\'"
-        status = misc.Popen([cmd], shell=True, stdout=subprocess.PIPE, 
-                                                         stderr=subprocess.PIPE)
-        
-        error = status.stderr.read()
-        if status.returncode or error:
-            raise ClusterManagmentError, 'condor_q returns error: %s' % error
+        q = self.query([str(id)], ["JobStatus", "HoldReason"], lim=1)
+        try:
+            status = q[0]["JobStatus"]
+        except Exception, error:
+            raise ClusterManagmentError, 'could not retrieve job query:\n%s' % error
+
+        s = self.status_map(status)
+
+        if s == 'H':
+            hold_reason = q[0]["HoldReason"]
+            logger.warning("ClusterId %s held with HoldReason: %s" % (str(id), hold_reason))
 
-        return status.stdout.readline().strip()
+        return s
     
-    jobstatus = {'0':'U', '1':'I','2':'R','3':'X','4':'C','5':'H','6':'E'}
     @check_interupt()
     @multiple_try(nb_try=10, sleep=10)
     def control(self, me_dir):
         """ control the status of a single job with it's cluster id """
-        
+
         if not self.submitted_ids:
             return 0, 0, 0, 0
-        
+
         packet = 15000
         idle, run, fail = 0, 0, 0
         ongoing = []
         for i in range(1+(len(self.submitted_ids)-1)//packet):
             start = i * packet
             stop = (i+1) * packet
-            cmd = "condor_q " + ' '.join(self.submitted_ids[start:stop]) + \
-            " -format \"%d \"   ClusterId " + \
-            " -format \"%d\\n\"  JobStatus "
+            q = self.query(self.submitted_ids[start:stop], ["ClusterId", "JobStatus", "HoldReason"])
 
-            status = misc.Popen([cmd], shell=True, stdout=subprocess.PIPE,
-                                                             stderr=subprocess.PIPE)
-            error = status.stderr.read()
-            if status.returncode or error:
-                raise ClusterManagmentError, 'condor_q returns error: %s' % error
-
-            for line in status.stdout:
-                id, status = line.strip().split()
-                status = self.jobstatus[status]
-                ongoing.append(id)
+            for job in q:
+                id, status = job["ClusterId"], self.status_map(job["JobStatus"])
+                ongoing.append(int(id))
+                if self.walltimes:
+                    maxwalltime = self.update_maxwalltime(id, self.walltimes)
+                    if maxwalltime:
+                        logger.info("Updated ClusterId {0} MaxWallTimeMins to: {1}".format(id, maxwalltime))
                 if status in ['I','U']:
                     idle += 1
                 elif status == 'R':
                     run += 1
+                elif status == 'H':
+                    released = False
+                    if self.hold_list:
+                        released = self.release_holdcodes(id, self.hold_list, int(self.max_shadows)) \
+                            if self.max_shadows else \
+                            self.release_holdcodes(id, self.hold_list)
+                    if not released:
+                        self.hold_msg = "ClusterId %s with HoldReason: %s" % (str(id), job["HoldReason"])
+                        fail += 1
                 elif status != 'C':
                     fail += 1
 
         for id in list(self.submitted_ids):
-            if id not in ongoing:
+            if int(id) not in ongoing:
                 status = self.check_termination(id)
                 if status == 'wait':
                     run += 1
